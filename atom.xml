<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yizhong&#39;s Blog</title>
  <subtitle>Does God Play Dice ?</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://eastonwang.github.io/"/>
  <updated>2016-11-30T07:59:35.357Z</updated>
  <id>https://eastonwang.github.io/</id>
  
  <author>
    <name>Yizhong Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ubuntu 16.04 配置 Tensorflow 深度学习环境</title>
    <link href="https://eastonwang.github.io/2016/11/30/Ubuntu-16-04-%E9%85%8D%E7%BD%AE-Tensorflow-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/"/>
    <id>https://eastonwang.github.io/2016/11/30/Ubuntu-16-04-配置-Tensorflow-深度学习环境/</id>
    <published>2016-11-30T07:13:50.000Z</published>
    <updated>2016-11-30T07:59:35.357Z</updated>
    
    <content type="html"><![CDATA[<p>最近，在实验室的主机上装好了深度学习的环境，因为配置步骤比较复杂，所以在这里记录一下，一是为了以后有问题的时候参考，二是可以给大家配置环境的时候提供一个借鉴。</p>
<p>我们配置的深度学习环境如下：</p>
<ul>
<li>显卡： GeForce GTX 1080 * 2</li>
<li>Nvidia 显卡驱动 367.57</li>
<li>Cuda Tookit 8.0</li>
<li>cuDNN v5</li>
<li>Tensorflow 0.12</li>
</ul>
<hr>
<p>下面开始进入安装步骤：</p>
<a id="more"></a>
<h3 id="1-显卡驱动"><a href="#1-显卡驱动" class="headerlink" title="1. 显卡驱动"></a>1. 显卡驱动</h3><p>安装过程需要在终端模式下进行(Desktop按<code>Ctrl+Alt+F1</code> 切换到终端界面)</p>
<h4 id="1-1-驱动安装文件下载"><a href="#1-1-驱动安装文件下载" class="headerlink" title="1.1 驱动安装文件下载"></a>1.1 驱动安装文件下载</h4><p>从 Nvidia <a href="http://www.nvidia.com/Download/index.aspx?lang=cn" target="_blank" rel="external">官网</a>选择并下载显卡对应的驱动安装文件，一般为 NVIDIA-Linux-x86_64_version_num.run </p>
<h4 id="1-2-卸载旧驱动，禁用自带驱动等"><a href="#1-2-卸载旧驱动，禁用自带驱动等" class="headerlink" title="1.2 卸载旧驱动，禁用自带驱动等"></a>1.2 卸载旧驱动，禁用自带驱动等</h4><ul>
<li><p>卸载可能存在的旧版本 nvidia 驱动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$sudo apt-get remove --purge nvidia*</div></pre></td></tr></table></figure>
</li>
<li><p>安装驱动可能需要的依赖(可选)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$sudo apt-get update</div><div class="line">$sudo apt-get install dkms build-essential linux-headers-generic</div></pre></td></tr></table></figure>
</li>
<li><p>把 nouveau 驱动加入黑名单</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$sudo nano /etc/modprobe.d/blacklist-nouveau.conf</div></pre></td></tr></table></figure>
</li>
</ul>
<p>加入如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">blacklist nouveau</div><div class="line">blacklist lbm-nouveau</div><div class="line">options nouveau modeset=0</div><div class="line">alias nouveau off</div><div class="line">alias lbm-nouveau off</div></pre></td></tr></table></figure></p>
<ul>
<li><p>禁用 nouveau 内核模块</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf</div><div class="line">$sudo update-initramfs -u</div></pre></td></tr></table></figure>
</li>
<li><p>重启计算机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo reboot</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="1-3-运行驱动安装文件并重启"><a href="#1-3-运行驱动安装文件并重启" class="headerlink" title="1.3. 运行驱动安装文件并重启"></a>1.3. 运行驱动安装文件并重启</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo sh  NVIDIA-Linux-x86_64_version_num.run</div></pre></td></tr></table></figure>
<h3 id="2-安装Cuda-Toolkit"><a href="#2-安装Cuda-Toolkit" class="headerlink" title="2. 安装Cuda Toolkit"></a>2. 安装Cuda Toolkit</h3><h4 id="2-1将桌面管理关闭，参考"><a href="#2-1将桌面管理关闭，参考" class="headerlink" title="2.1将桌面管理关闭，参考:"></a>2.1将桌面管理关闭，<a href="https://gist.github.com/bearpaw/c38ef18ec45ba6548ec0" target="_blank" rel="external">参考</a>:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo service lightdm stop</div></pre></td></tr></table></figure>
<h4 id="2-2从官网下载相应的安装包，并按照提示安装即可。"><a href="#2-2从官网下载相应的安装包，并按照提示安装即可。" class="headerlink" title="2.2从官网下载相应的安装包，并按照提示安装即可。"></a>2.2从<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">官网</a>下载相应的安装包，并按照提示安装即可。</h4><p>我们选择了安转deb包，通过以下命令进行安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo dpkg -i cuda-repo-&lt;distro&gt;_&lt;version&gt;_&lt;architecture&gt;.deb</div><div class="line">sudo apt update</div><div class="line">sudo apt install cuda</div><div class="line">sudo reboot</div></pre></td></tr></table></figure>
<h3 id="3-安装cuDNN"><a href="#3-安装cuDNN" class="headerlink" title="3. 安装cuDNN"></a>3. 安装cuDNN</h3><h4 id="3-1-从官网下载最新的安装包，解压后将文件复制到对应的位置："><a href="#3-1-从官网下载最新的安装包，解压后将文件复制到对应的位置：" class="headerlink" title="3.1 从官网下载最新的安装包，解压后将文件复制到对应的位置："></a>3.1 从<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="external">官网</a>下载最新的安装包，解压后将文件复制到对应的位置：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz</div><div class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</div><div class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</div><div class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure>
<h4 id="3-2-配置环境变量："><a href="#3-2-配置环境变量：" class="headerlink" title="3.2 配置环境变量："></a>3.2 配置环境变量：</h4><p>打开<code>~/.bashrc</code>文件，在末尾添加以下内容，注意nvidia-367版本号可能会有不同：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-367</div><div class="line">export CUDA_HOME=/usr/local/cuda</div><div class="line">export PATH=$PATH:/usr/local/cuda/bin</div></pre></td></tr></table></figure></p>
<h3 id="4-安装tensorflow"><a href="#4-安装tensorflow" class="headerlink" title="4. 安装tensorflow"></a>4. 安装tensorflow</h3><p>目前, tensorflow 0.12已经支持<code>pip</code>安装，可以直接参考官方<a href="https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#using-pip" target="_blank" rel="external">教程</a>进行。</p>
<hr>
<p>到这里，整个环境就配置好了，可以运行<code>ipython</code>之后<code>import tensorflow</code>进行测试，也可以通过跑tensorflow源码中的例子进行测试，比如<code>tensorflow/tensorflow/models/image/mnist</code>中的CNN模型，在这里不再详述。</p>
<hr>
<p>参考：</p>
<ol>
<li>官方文档：<a href="https://www.tensorflow.org/versions/r0.12/get_started/" target="_blank" rel="external">https://www.tensorflow.org/versions/r0.12/get_started/</a></li>
<li>Install tensorflow with cuda: <a href="http://city.shaform.com/blog/2016/10/31/install-tensorflow-with-cuda.html" target="_blank" rel="external">http://city.shaform.com/blog/2016/10/31/install-tensorflow-with-cuda.html</a></li>
<li>Ubuntu16.04 英伟达显卡驱动：<a href="https://gist.github.com/dangbiao1991/7825db1d17df9231f4101f034ecd5a2b" target="_blank" rel="external">https://gist.github.com/dangbiao1991/7825db1d17df9231f4101f034ecd5a2b</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近，在实验室的主机上装好了深度学习的环境，因为配置步骤比较复杂，所以在这里记录一下，一是为了以后有问题的时候参考，二是可以给大家配置环境的时候提供一个借鉴。&lt;/p&gt;
&lt;p&gt;我们配置的深度学习环境如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显卡： GeForce GTX 1080 * 2&lt;/li&gt;
&lt;li&gt;Nvidia 显卡驱动 367.57&lt;/li&gt;
&lt;li&gt;Cuda Tookit 8.0&lt;/li&gt;
&lt;li&gt;cuDNN v5&lt;/li&gt;
&lt;li&gt;Tensorflow 0.12&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;下面开始进入安装步骤：&lt;/p&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://eastonwang.github.io/tags/Deep-Learning/"/>
    
      <category term="Tensorflow" scheme="https://eastonwang.github.io/tags/Tensorflow/"/>
    
      <category term="Ubuntu" scheme="https://eastonwang.github.io/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>使用Makefile来编译Tex文件</title>
    <link href="https://eastonwang.github.io/2016/11/29/%E4%BD%BF%E7%94%A8Makefile%E6%9D%A5%E7%BC%96%E8%AF%91Tex%E6%96%87%E4%BB%B6/"/>
    <id>https://eastonwang.github.io/2016/11/29/使用Makefile来编译Tex文件/</id>
    <published>2016-11-29T13:03:24.000Z</published>
    <updated>2016-11-29T13:35:57.747Z</updated>
    
    <content type="html"><![CDATA[<p>最近在新配置的Linux机器上面写论文，因为只是小的改动，不想用Texmaker之类的IDE。而且因为IDE会产生很多的依赖和log文件，用dropbox同步的时候比较烦人。所以，转向了命令行来编译tex文件。当然，每次都敲latex，biblatex，pdflatex还是很烦人的，于是自己写了一个Makefile，这样，通过make命令就可以编译和查看文章了。</p>
<p>首先，需要安装texlive，也就是整个tex包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install texlive</div></pre></td></tr></table></figure>
<p>然后，在新建好的tex目录下，新建Makefile文件，文件内容如下：<br><a id="more"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">filename=主tex文件名，比如paper</div><div class="line"></div><div class="line">all: pdf clean read</div><div class="line"></div><div class="line">pdf: ps</div><div class="line">	ps2pdf $&#123;filename&#125;.ps</div><div class="line"></div><div class="line">pdf-print: ps</div><div class="line">	ps2pdf -dColorConversionStrategy=/LeaveColorUnchanged -dPDFSETTINGS=/printer $&#123;filename&#125;.ps</div><div class="line"></div><div class="line">text: html</div><div class="line">	html2text -width 100 -style pretty $&#123;filename&#125;/$&#123;filename&#125;.html | sed -n &apos;/./,$$p&apos; | head -n-2 &gt;$&#123;filename&#125;.txt</div><div class="line"></div><div class="line">html:</div><div class="line">	@#latex2html -split +0 -info &quot;&quot; -no_navigation $&#123;filename&#125;</div><div class="line">	htlatex $&#123;filename&#125;</div><div class="line"></div><div class="line">ps:	dvi</div><div class="line">	dvips -t letter $&#123;filename&#125;.dvi</div><div class="line"></div><div class="line">dvi:</div><div class="line">	latex $&#123;filename&#125;</div><div class="line">	bibtex $&#123;filename&#125;</div><div class="line">	latex $&#123;filename&#125;</div><div class="line">	latex $&#123;filename&#125;</div><div class="line"></div><div class="line">read:</div><div class="line">	evince $&#123;filename&#125;.pdf &amp;</div><div class="line"></div><div class="line">aread:</div><div class="line">	acroread $&#123;filename&#125;.pdf</div><div class="line"></div><div class="line">clean:</div><div class="line">	rm -f *.toc *.aux *.log *.out *.blg *.bbl *.dvi *.ps *.gz</div><div class="line"></div><div class="line">cleanall:</div><div class="line">	rm -f $&#123;filename&#125;.pdf *.toc *.aux *.log *.out *.blg *.bbl *.dvi *.ps *.gz</div></pre></td></tr></table></figure>
<p>其中, <code>all: pdf clean read</code> 表示当执行make命令时，程序将会先后执行<code>pdf</code>、<code>clean</code>、<code>read</code>这三个命令对应的内容。如果不需要<code>clean</code>和<code>read</code>则可以删掉。</p>
<p>之后，编译tex和查看pdf只需要执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make</div></pre></td></tr></table></figure></p>
<p>如果想删除所有的log文件，可执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make clean</div></pre></td></tr></table></figure></p>
<p>如果想连pdf文件也一起删除，可执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make cleanall</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在新配置的Linux机器上面写论文，因为只是小的改动，不想用Texmaker之类的IDE。而且因为IDE会产生很多的依赖和log文件，用dropbox同步的时候比较烦人。所以，转向了命令行来编译tex文件。当然，每次都敲latex，biblatex，pdflatex还是很烦人的，于是自己写了一个Makefile，这样，通过make命令就可以编译和查看文章了。&lt;/p&gt;
&lt;p&gt;首先，需要安装texlive，也就是整个tex包：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sudo apt-get install texlive&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;然后，在新建好的tex目录下，新建Makefile文件，文件内容如下：&lt;br&gt;
    
    </summary>
    
    
      <category term="Latex" scheme="https://eastonwang.github.io/tags/Latex/"/>
    
      <category term="tools" scheme="https://eastonwang.github.io/tags/tools/"/>
    
  </entry>
  
  <entry>
    <title>Several Methods to Go Over GFW</title>
    <link href="https://eastonwang.github.io/2016/11/17/Several-Methods-to-Go-Over-GFW/"/>
    <id>https://eastonwang.github.io/2016/11/17/Several-Methods-to-Go-Over-GFW/</id>
    <published>2016-11-17T01:02:10.000Z</published>
    <updated>2016-11-30T07:53:53.211Z</updated>
    
    <content type="html"><![CDATA[<p>Years ago, I started to climb over GFW and embrace a brand new Internet world. It’s fantac. Even though there are many unreal rumors about China, I still find large amounts of useful information and Google definitely improved my efficiency.</p>
<p>There are various of ways to fuck GFW. I used to use shadowsocks but now I turn to hosts and IPV6. So I’d like to make a summary of these methods and I would continally add more methods if I find them really useful.</p>
<h3 id="Github-Education-Package"><a href="#Github-Education-Package" class="headerlink" title="Github Education Package"></a><a href="https://education.github.com/" target="_blank" rel="external">Github Education Package</a></h3><p>Github education package contains dozens of software to help students work and study. Most of all, it supplies a $50 credits for <a href="https://www.digitalocean.com/" target="_blank" rel="external">digital ocean</a>, which can be used to set up your vps. According to my test, the Sanfrancisco hosts and Singapore hosts are faster than others in China. </p>
<h3 id="VPN"><a href="#VPN" class="headerlink" title="VPN"></a>VPN</h3><p>This is a classic way to go over GFW. You can set up PPTP, L2TP or IPSec VPN servers on your own vps. Or you can buy one account. Here are some famous websites for this:</p>
<ol>
<li><a href="https://www.ytpub.com/" target="_blank" rel="external">云梯</a></li>
<li><a href="https://bestvpnchina.net/%E5%85%8D%E8%B4%B9vpn%E6%8E%A8%E8%8D%90/" target="_blank" rel="external">Recommendations from other website.</a></li>
</ol>
<a id="more"></a>
<h3 id="Lantern"><a href="#Lantern" class="headerlink" title="Lantern"></a>Lantern</h3><p>Some people recommend this months ago. I didn’t try it but they said it’s fascinating. You can explore it at its <a href="https://getlantern.org/" target="_blank" rel="external">official website</a>.</p>
<p>And this is a <a href="https://program-think.blogspot.com/2015/08/gfw-lantern.html" target="_blank" rel="external">blog</a> for reference. </p>
<h3 id="Shadowsocks"><a href="#Shadowsocks" class="headerlink" title="Shadowsocks"></a>Shadowsocks</h3><p>Shadowsocks is now very popular in China because of its security and all-platform support. I used it for nearly two years on my Android phone and some of my servers. It’s easy for a programmer or handyman to set up a shadowsocks server on his own vps. You can follow the steps from this <a href="http://shadowsocks.blogspot.com/" target="_blank" rel="external">blog</a>. It’s a complete tutorial.</p>
<h3 id="Hosts"><a href="#Hosts" class="headerlink" title="Hosts"></a>Hosts</h3><p>These days I found this approach quite fascinating in its speed and fast configuration. Here I recommend two well-maintained repositories for use:</p>
<ol>
<li><a href="https://github.com/racaljk/hosts" target="_blank" rel="external">IPV4 hosts</a></li>
<li><a href="https://github.com/lennylxx/ipv6-hosts" target="_blank" rel="external">IPV6 hosts</a></li>
</ol>
<p>For education net user, I greatly recommend you to use the IPV6 version or combine them together. For ordinary users, the first one also works well.</p>
<h3 id="DNS-server"><a href="#DNS-server" class="headerlink" title="DNS server"></a>DNS server</h3><p>This is a alternative method to Hosts. But I should emphasize here it’s not stable. Since some dns requests will be detected by GFW and GFW will return you with a dummy ip address. Also, sometimes the dns servers may get polluted.</p>
<p>However, despite its unstability, this method works in my iPhone/iPad device, since you cannot change the hosts file without rooting the device.</p>
<p>Good dns servers are listed here:</p>
<ol>
<li>Google IPV4 DNS: 8.8.8.8 nad 8.8.4.4</li>
<li>Google IPV6 DNS: 2001:4860:4860::8888 and 2001:4860:4860::8844</li>
<li>OpenDNS IPV4 and IPV6 mixed DNS (IPV6 first): 2620:0:ccc::2 and 2620:0:ccd::2</li>
</ol>
<p>To summarize, if you are in education net, like myself, I greatly suggest the Hosts method, because you can take advantage of IPV6 and the access is much faster. And for Iphone/Ipad device with out root, you can use the IPV6 dns server. Even though it’s not very stable, I find most of useful websites are always available. </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Years ago, I started to climb over GFW and embrace a brand new Internet world. It’s fantac. Even though there are many unreal rumors about China, I still find large amounts of useful information and Google definitely improved my efficiency.&lt;/p&gt;
&lt;p&gt;There are various of ways to fuck GFW. I used to use shadowsocks but now I turn to hosts and IPV6. So I’d like to make a summary of these methods and I would continally add more methods if I find them really useful.&lt;/p&gt;
&lt;h3 id=&quot;Github-Education-Package&quot;&gt;&lt;a href=&quot;#Github-Education-Package&quot; class=&quot;headerlink&quot; title=&quot;Github Education Package&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://education.github.com/&quot;&gt;Github Education Package&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Github education package contains dozens of software to help students work and study. Most of all, it supplies a $50 credits for &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;digital ocean&lt;/a&gt;, which can be used to set up your vps. According to my test, the Sanfrancisco hosts and Singapore hosts are faster than others in China. &lt;/p&gt;
&lt;h3 id=&quot;VPN&quot;&gt;&lt;a href=&quot;#VPN&quot; class=&quot;headerlink&quot; title=&quot;VPN&quot;&gt;&lt;/a&gt;VPN&lt;/h3&gt;&lt;p&gt;This is a classic way to go over GFW. You can set up PPTP, L2TP or IPSec VPN servers on your own vps. Or you can buy one account. Here are some famous websites for this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.ytpub.com/&quot;&gt;云梯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://bestvpnchina.net/%E5%85%8D%E8%B4%B9vpn%E6%8E%A8%E8%8D%90/&quot;&gt;Recommendations from other website.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="tech" scheme="https://eastonwang.github.io/tags/tech/"/>
    
      <category term="GFW" scheme="https://eastonwang.github.io/tags/GFW/"/>
    
  </entry>
  
  <entry>
    <title>New Workstation for Deep Learning</title>
    <link href="https://eastonwang.github.io/2016/11/13/New-Workstation-for-Deep-Learning/"/>
    <id>https://eastonwang.github.io/2016/11/13/New-Workstation-for-Deep-Learning/</id>
    <published>2016-11-13T07:45:50.000Z</published>
    <updated>2016-11-29T13:33:58.337Z</updated>
    
    <content type="html"><![CDATA[<p>Our lab is equiped with a new workstation recently. I spent some time studying how to assembly such a computer for deep learning and configure the deep learning environment. Finally I made it and here is a picture of the inner architecure.</p>
<p><img src="/images/workstation.jpg" alt="New workstation"></p>
<p>Quite cool, aha?</p>
<a id="more"></a>
<p>We have one Intel 6850K CPU and two GTX 1080 gpu cards in it, which I think is enough for our small lab to do some deep learning experiments in NLP. Of course, we don’t want to compete with other big group in the Neural Machine Learning field.</p>
<p><img src="/images/gpu-card.png" alt="GPU screenshot"></p>
<p>And now my work space is like this:</p>
<p><img src="/images/workspace.jpg" alt="Work space"><br>I have to say it’s quite comfortable and I even want to sleep here when the cold winter comes!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Our lab is equiped with a new workstation recently. I spent some time studying how to assembly such a computer for deep learning and configure the deep learning environment. Finally I made it and here is a picture of the inner architecure.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/workstation.jpg&quot; alt=&quot;New workstation&quot;&gt;&lt;/p&gt;
&lt;p&gt;Quite cool, aha?&lt;/p&gt;
    
    </summary>
    
    
      <category term="engadget" scheme="https://eastonwang.github.io/tags/engadget/"/>
    
      <category term="tech" scheme="https://eastonwang.github.io/tags/tech/"/>
    
      <category term="happy" scheme="https://eastonwang.github.io/tags/happy/"/>
    
  </entry>
  
  <entry>
    <title>New start</title>
    <link href="https://eastonwang.github.io/2016/11/12/New-start/"/>
    <id>https://eastonwang.github.io/2016/11/12/New-start/</id>
    <published>2016-11-12T12:33:49.000Z</published>
    <updated>2016-11-13T07:14:32.762Z</updated>
    
    <content type="html"><![CDATA[<p>After the first two headache months of my graduate study, I’m ready to re-launch this blog today. </p>
<p>I’m going to write some of my technical practices, research strucggles and interesting daily stories here. Hopefully I can continue this good habit to write blogs sometimes.</p>
<p>And thanks for your visiting and hope you can enjoy something here.</p>
<p>Now let’s start!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;After the first two headache months of my graduate study, I’m ready to re-launch this blog today. &lt;/p&gt;
&lt;p&gt;I’m going to write some of my t
    
    </summary>
    
    
      <category term="blog-self" scheme="https://eastonwang.github.io/tags/blog-self/"/>
    
  </entry>
  
</feed>
