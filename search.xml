<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Ubuntu 16.04 配置 Tensorflow 深度学习环境]]></title>
      <url>%2F2016%2F11%2F30%2FUbuntu-16-04-%E9%85%8D%E7%BD%AE-Tensorflow-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%2F</url>
      <content type="text"><![CDATA[最近，在实验室的主机上装好了深度学习的环境，因为配置步骤比较复杂，所以在这里记录一下，一是为了以后有问题的时候参考，二是可以给大家配置环境的时候提供一个借鉴。 我们配置的深度学习环境如下： 显卡： GeForce GTX 1080 * 2 Nvidia 显卡驱动 367.57 Cuda Tookit 8.0 cuDNN v5 Tensorflow 0.12 下面开始进入安装步骤： 1. 显卡驱动安装过程需要在终端模式下进行(Desktop按Ctrl+Alt+F1 切换到终端界面) 1.1 驱动安装文件下载从 Nvidia 官网选择并下载显卡对应的驱动安装文件，一般为 NVIDIA-Linux-x86_64_version_num.run 1.2 卸载旧驱动，禁用自带驱动等 卸载可能存在的旧版本 nvidia 驱动 1$sudo apt-get remove --purge nvidia* 安装驱动可能需要的依赖(可选) 12$sudo apt-get update$sudo apt-get install dkms build-essential linux-headers-generic 把 nouveau 驱动加入黑名单 1$sudo nano /etc/modprobe.d/blacklist-nouveau.conf 加入如下内容：12345blacklist nouveaublacklist lbm-nouveauoptions nouveau modeset=0alias nouveau offalias lbm-nouveau off 禁用 nouveau 内核模块 12$echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf$sudo update-initramfs -u 重启计算机 1sudo reboot 1.3. 运行驱动安装文件并重启1sudo sh NVIDIA-Linux-x86_64_version_num.run 2. 安装Cuda Toolkit2.1将桌面管理关闭，参考:1sudo service lightdm stop 2.2从官网下载相应的安装包，并按照提示安装即可。我们选择了安转deb包，通过以下命令进行安装： 1234sudo dpkg -i cuda-repo-&lt;distro&gt;_&lt;version&gt;_&lt;architecture&gt;.debsudo apt updatesudo apt install cudasudo reboot 3. 安装cuDNN3.1 从官网下载最新的安装包，解压后将文件复制到对应的位置：1234tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgzsudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 3.2 配置环境变量：打开~/.bashrc文件，在末尾添加以下内容，注意nvidia-367版本号可能会有不同：123export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-367export CUDA_HOME=/usr/local/cudaexport PATH=$PATH:/usr/local/cuda/bin 4. 安装tensorflow目前, tensorflow 0.12已经支持pip安装，可以直接参考官方教程进行。 到这里，整个环境就配置好了，可以运行ipython之后import tensorflow进行测试，也可以通过跑tensorflow源码中的例子进行测试，比如tensorflow/tensorflow/models/image/mnist中的CNN模型，在这里不再详述。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Makefile来编译Tex文件]]></title>
      <url>%2F2016%2F11%2F29%2F%E4%BD%BF%E7%94%A8Makefile%E6%9D%A5%E7%BC%96%E8%AF%91Tex%E6%96%87%E4%BB%B6%2F</url>
      <content type="text"><![CDATA[最近在新配置的Linux机器上面写论文，因为只是小的改动，不想用Texmaker之类的IDE。而且因为IDE会产生很多的依赖和log文件，用dropbox同步的时候比较烦人。所以，转向了命令行来编译tex文件。当然，每次都敲latex，biblatex，pdflatex还是很烦人的，于是自己写了一个Makefile，这样，通过make命令就可以编译和查看文章了。 首先，需要安装texlive，也就是整个tex包： 1sudo apt-get install texlive 然后，在新建好的tex目录下，新建Makefile文件，文件内容如下： 12345678910111213141516171819202122232425262728293031323334353637filename=主tex文件名，比如paperall: pdf clean readpdf: ps ps2pdf $&#123;filename&#125;.pspdf-print: ps ps2pdf -dColorConversionStrategy=/LeaveColorUnchanged -dPDFSETTINGS=/printer $&#123;filename&#125;.pstext: html html2text -width 100 -style pretty $&#123;filename&#125;/$&#123;filename&#125;.html | sed -n &apos;/./,$$p&apos; | head -n-2 &gt;$&#123;filename&#125;.txthtml: @#latex2html -split +0 -info &quot;&quot; -no_navigation $&#123;filename&#125; htlatex $&#123;filename&#125;ps: dvi dvips -t letter $&#123;filename&#125;.dvidvi: latex $&#123;filename&#125; bibtex $&#123;filename&#125; latex $&#123;filename&#125; latex $&#123;filename&#125;read: evince $&#123;filename&#125;.pdf &amp;aread: acroread $&#123;filename&#125;.pdfclean: rm -f *.toc *.aux *.log *.out *.blg *.bbl *.dvi *.ps *.gzcleanall: rm -f $&#123;filename&#125;.pdf *.toc *.aux *.log *.out *.blg *.bbl *.dvi *.ps *.gz 其中, all: pdf clean read 表示当执行make命令时，程序将会先后执行pdf、clean、read这三个命令对应的内容。如果不需要clean和read则可以删掉。 之后，编译tex和查看pdf只需要执行：1make 如果想删除所有的log文件，可执行：1make clean 如果想连pdf文件也一起删除，可执行：1make cleanall]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Several Methods to Go Over GFW]]></title>
      <url>%2F2016%2F11%2F17%2FSeveral-Methods-to-Go-Over-GFW%2F</url>
      <content type="text"><![CDATA[Years ago, I started to climb over GFW and embrace a brand new Internet world. It’s fantac. Even though there are many unreal rumors about China, I still find large amounts of useful information and Google definitely improved my efficiency. There are various of ways to fuck GFW. I used to use shadowsocks but now I turn to hosts and IPV6. So I’d like to make a summary of these methods and I would continally add more methods if I find them really useful. Github Education PackageGithub education package contains dozens of software to help students work and study. Most of all, it supplies a $50 credits for digital ocean, which can be used to set up your vps. According to my test, the Sanfrancisco hosts and Singapore hosts are faster than others in China. VPNThis is a classic way to go over GFW. You can set up PPTP, L2TP or IPSec VPN servers on your own vps. Or you can buy one account. Here are some famous websites for this: 云梯 Recommendations from other website. LanternSome people recommend this months ago. I didn’t try it but they said it’s fascinating. You can explore it at its official website. And this is a blog for reference. ShadowsocksShadowsocks is now very popular in China because of its security and all-platform support. I used it for nearly two years on my Android phone and some of my servers. It’s easy for a programmer or handyman to set up a shadowsocks server on his own vps. You can follow the steps from this blog. It’s a complete tutorial. HostsThese days I found this approach quite fascinating in its speed and fast configuration. Here I recommend two well-maintained repositories for use: IPV4 hosts IPV6 hosts For education net user, I greatly recommend you to use the IPV6 version or combine them together. For ordinary users, the first one also works well. DNS serverThis is a alternative method to Hosts. But I should emphasize here it’s not stable. Since some dns requests will be detected by GFW and GFW will return you with a dummy ip address. Also, sometimes the dns servers may get polluted. However, despite its unstability, this method works in my iPhone/iPad device, since you cannot change the hosts file without rooting the device. Good dns servers are listed here: Google IPV4 DNS: 8.8.8.8 nad 8.8.4.4 Google IPV6 DNS: 2001:4860:4860::8888 and 2001:4860:4860::8844 OpenDNS IPV4 and IPV6 mixed DNS (IPV6 first): 2620:0:ccc::2 and 2620:0:ccd::2 To summarize, if you are in education net, like myself, I greatly suggest the Hosts method, because you can take advantage of IPV6 and the access is much faster. And for Iphone/Ipad device with out root, you can use the IPV6 dns server. Even though it’s not very stable, I find most of useful websites are always available.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[New Workstation for Deep Learning]]></title>
      <url>%2F2016%2F11%2F13%2FNew-Workstation-for-Deep-Learning%2F</url>
      <content type="text"><![CDATA[Our lab is equiped with a new workstation recently. I spent some time studying how to assembly such a computer for deep learning and configure the deep learning environment. Finally I made it and here is a picture of the inner architecure. Quite cool, aha? We have one Intel 6850K CPU and two GTX 1080 gpu cards in it, which I think is enough for our small lab to do some deep learning experiments in NLP. Of course, we don’t want to compete with other big group in the Neural Machine Learning field. And now my work space is like this: I have to say it’s quite comfortable and I even want to sleep here when the cold winter comes!]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[New start]]></title>
      <url>%2F2016%2F11%2F12%2FNew-start%2F</url>
      <content type="text"><![CDATA[After the first two headache months of my graduate study, I’m ready to re-launch this blog today. I’m going to write some of my technical practices, research strucggles and interesting daily stories here. Hopefully I can continue this good habit to write blogs sometimes. And thanks for your visiting and hope you can enjoy something here. Now let’s start!]]></content>
    </entry>

    
  
  
</search>
